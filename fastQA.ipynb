{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3\n",
    "### Actividad 7\n",
    "El modelo que se pensó ocupar es uno basado en el paper de [Weissenborn et al](https://arxiv.org/abs/1703.04816). Este modelo plantea un baseline simple para implementar una red neuronal que permita resolver el problema de Pregunta/Respuesta. De manera general, el modelo propuesto se muestra en la siguiente figura:\n",
    "![Modelo propuesto para resolver el problema de Pregunta/Respuesta](https://i.imgur.com/KnnCaLS.png)\n",
    "\n",
    "Para modelar los documentos de manera eficiente se decidió tomar el modelo Wor2Vec, para lo cual se crea un diccionario basado en todas las palabras disponibles en el set de parrafos y preguntas.\n",
    "\n",
    "Después de crear el modelo Inicialmente se tiene dos modelos, uno que permita retener el conocimiento de los parrafos y otro modelo que sea para retener el conocimiento de las preguntas. La estructura de ambos modelos esta dada por:\n",
    "- Una capa de encoding, que permite obtener un documento en su versión vectorial, donde cada palabra antes de ser ingresada a la red es reemplazada por un número entero que representa su posición en el vector de palabras.\n",
    "- Una capa recurrente del tipo bidireccional para retener el conocimiento.\n",
    "\n",
    "En este modelo se eligió una capa recurrente bidireccional debido a que esta entiende mucho mejor el contexto ya que debido a su diseño este puede retener la información respecto al [pasado y futuro](https://www.quora.com/When-should-one-use-bidirectional-LSTM-as-opposed-to-normal-LSTM). Esto permite mejorar de cierta manera el rendimiento de la red neuronal.\n",
    "\n",
    "El siguiente paso es tener una capa de interacción que concatena las entradas de ambos modelos, esta capa de concatenación se le pasa a otra capa recurrente del tipo LSTM bidireccional y las salidas se envian a una capa densa que sirve de clasificador, el cual devuelve la posición del primer carácter de la respuesta en el párrafo.\n",
    "\n",
    "Para el proceso de modelamiento de los documentos se decidió usar la librería Gensim que permite generar un modelo Word2Vec y ser añadido como la capa de encoding a una red neuronal hecha en Keras.\n",
    "\n",
    "### Actividad 8\n",
    "Esta red neuronal fue entrenada en una GPU Nvidia 1080Ti, haciendo uso de la librería Keras corriendo bajo el backend de tensorflow. Inicialmente se realiza la configuración básica del entorno, se importan las librerías básicas y necesarias para el proceso de entrenamiento y por último se agrega un pequeño segmento de código que se comunica con el backend en Tensorflow para evitar que la GPU sea llenada de golpe y se pida memoria \"on-demand\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import gensim.parsing.preprocessing as p\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dropout, Dense, Input, LSTM, Bidirectional, concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "# Dynamic allocation of GPU memory\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección de código se procede a la inicialización del dataset. La implementación consiste en inicialmente leer el archivo en formato json y la posterior lectura de los parrafos, las preguntas y las respuestas. Para el caso de los parrafos y las preguntas se sigue un proceso de post procesamiento en el cual se elimina las puntuaciones y espacios que están demas. En este caso no se hace un proceso de stemming ya que se tiene la hipótesis de que la red necesita de más contexto al respecto de tiempos, pluraridad, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n",
      "Finished reading and preprocessing documents\n"
     ]
    }
   ],
   "source": [
    "# Dataset reading\n",
    "with(open('train-v1.1.json')) as json_data:\n",
    "    d = json.load(json_data)\n",
    "\n",
    "dataset = d['data']\n",
    "print(len(dataset))\n",
    "\n",
    "context_list = []\n",
    "question_list = []\n",
    "answer_list = []\n",
    "answer_start = []\n",
    "answer_end = []\n",
    "\n",
    "context_size = 600\n",
    "question_size = 50\n",
    "\n",
    "CUSTOM_FILTER = [\n",
    "    lambda x: x.lower(), p.strip_tags, p.strip_punctuation,\n",
    "    p.strip_multiple_whitespaces\n",
    "]\n",
    "\n",
    "for article in dataset:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = p.preprocess_string(paragraph['context'], CUSTOM_FILTER)\n",
    "        if len(context) > context_size:\n",
    "            context_size = len(context)\n",
    "\n",
    "        for qa in paragraph['qas']:\n",
    "            question = p.preprocess_string(qa['question'], CUSTOM_FILTER)\n",
    "            if len(question) > question_size:\n",
    "                question_size = len(question)\n",
    "\n",
    "            for answer in qa['answers']:\n",
    "                context_list.append(context)\n",
    "                question_list.append(question)\n",
    "                answer_list.append(answer['text'])\n",
    "                answer_start.append(answer['answer_start'])\n",
    "                answer_end.append(answer['answer_start'] + len(answer['text']) - 1)\n",
    "\n",
    "print(\"Finished reading and preprocessing documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es entrenar el modelo Word2Vec, para esto se hace uso de la librería *Word2Vec*, este vector se crea con un tamaño de 200 para las features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training W2V model\n",
      "Finished to train W2V model\n"
     ]
    }
   ],
   "source": [
    "# Training Word2Vec model\n",
    "print(\"Training W2V model\")\n",
    "\n",
    "modelW2V = gensim.models.Word2Vec(context_list + question_list, size=200, workers=8, min_count=1, iter=20)\n",
    "\n",
    "print(\"Finished to train W2V model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.4859297573566437),\n",
       " ('pet', 0.4292300343513489),\n",
       " ('groomers', 0.41012632846832275),\n",
       " ('poultry', 0.40378862619400024),\n",
       " ('caretakers', 0.4020272195339203),\n",
       " ('familiaris', 0.3992404341697693),\n",
       " ('chicken', 0.38795578479766846),\n",
       " ('breed', 0.38742366433143616),\n",
       " ('canis', 0.38202208280563354),\n",
       " ('wolf', 0.36578139662742615)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.most_similar(positive=['dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de poder entrenar el dataset, es necesario pasar las estructuras de datos armadas a un formato más legible para Keras, el cual son *Numpy arrays*. Se procede a crear los arreglos necesarios para los datos de entrada y salida que se ocupará en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training dataset\n",
      "3126\n"
     ]
    }
   ],
   "source": [
    "# Prepare training dataset\n",
    "print(\"Preparing training dataset\")\n",
    "context_array = np.zeros((len(context_list), context_size), dtype='int32')\n",
    "question_array = np.zeros((len(question_list), question_size), dtype='int32')\n",
    "start_array = np.zeros((len(answer_start),), dtype='int32')\n",
    "end_array = np.zeros(len(answer_end,), dtype='int32')\n",
    "\n",
    "for i in range(len(context_list)):\n",
    "    for j in range(len(context_list[i])):\n",
    "        context_array[i][j] = modelW2V.wv.vocab[context_list[i][j]].index\n",
    "\n",
    "for i in range(len(question_list)):\n",
    "    for j in range(len(question_list[i])):\n",
    "        question_array[i][j] = modelW2V.wv.vocab[question_list[i][j]].index\n",
    "\n",
    "for i in range(len(answer_start)):\n",
    "    start_array[i] = answer_start[i]\n",
    "    \n",
    "for i in range(len(answer_start)):\n",
    "    end_array[i] = answer_end[i]\n",
    "    \n",
    "max_start = np.amax(start_array)\n",
    "max_end = np.amax(end_array)\n",
    "print(max_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la creación del modelo en este caso se usa la API funcional de Keras, debido a que el modelo Secuencial que ofrece no tiene la flexibilidad necesaria para poder crear el modelo propuesto. Es por eso que se crea el modelo en base a tensores y la API funcional de modelos de Keras.\n",
    "En esta parte, se crea el modelo que se encarga de aprender las características del contexto o párrafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Model\n",
    "context_input = Input(shape=(context_size, ), dtype='int32', name='context_input')\n",
    "x = modelW2V.wv.get_keras_embedding()(context_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True), merge_mode='mul')(x)\n",
    "drop1 = Dropout(0.5)(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente se crea el modelo que se encarga de aprender las características relacionadas a las preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Model\n",
    "question_input = Input(shape=(question_size,), dtype='int32', name='question_input')\n",
    "x = modelW2V.wv.get_keras_embedding()(question_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True), merge_mode='mul')(x)\n",
    "drop2 = Dropout(0.5)(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se crea la capa de interacción, el cuál se encarga de unir los dos modelos anteriores, para esto se usa el método de concatenación. Seguido de esto se agrega otra capa LSTM bidireccional y las dos salidas que se necesitan en la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge model\n",
    "merge_layer = concatenate([drop1, drop2], axis=1)\n",
    "lstm = Bidirectional(LSTM(512, return_sequences=False), merge_mode='mul')(merge_layer)\n",
    "softmax1 = Dense(max_start, activation='softmax')(lstm)\n",
    "softmax2 = Dense(max_end, activation='softmax')(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto el modelo es creado y se lo compila. En este caso se usa la función de pérdida \"Sparce Categorical CrossEntropy\". Y por último, se genera un resumen de la estructura de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context_input (InputLayer)      (None, 679)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 679, 200)     17265200    context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 200)      17265200    question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 679, 256)     935936      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 256)      935936      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 679, 256)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 256)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 729, 256)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 512)          3149824     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3126)         1603638     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3135)         1608255     bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 42,763,989\n",
      "Trainable params: 8,233,589\n",
      "Non-trainable params: 34,530,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[context_input, question_input], outputs=[softmax1, softmax2])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a la fase de entrenamiento y posterior guardado de los pesos en disco. Para la fase de entrenamiento, debido al tamaño del dataset, se deicidó realizar el entrenamiento por partes, siendo que para cada 30 iteraciones se hace un entrenamiento con una sección de 10000 datos del datase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 162s 16ms/step - loss: 14.4568 - dense_1_loss: 7.1960 - dense_2_loss: 7.2608 - dense_1_acc: 0.0230 - dense_2_acc: 0.0019\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 13.3812 - dense_1_loss: 6.6479 - dense_2_loss: 6.7333 - dense_1_acc: 0.0244 - dense_2_acc: 0.0061\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 13.2717 - dense_1_loss: 6.5903 - dense_2_loss: 6.6814 - dense_1_acc: 0.0292 - dense_2_acc: 0.0064\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 13.1375 - dense_1_loss: 6.5162 - dense_2_loss: 6.6213 - dense_1_acc: 0.0349 - dense_2_acc: 0.0067\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 12.9636 - dense_1_loss: 6.4292 - dense_2_loss: 6.5344 - dense_1_acc: 0.0366 - dense_2_acc: 0.0088\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 12.7677 - dense_1_loss: 6.3324 - dense_2_loss: 6.4353 - dense_1_acc: 0.0368 - dense_2_acc: 0.0107\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 12.5584 - dense_1_loss: 6.2301 - dense_2_loss: 6.3283 - dense_1_acc: 0.0366 - dense_2_acc: 0.0126\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 12.3377 - dense_1_loss: 6.1209 - dense_2_loss: 6.2168 - dense_1_acc: 0.0402 - dense_2_acc: 0.0180\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 12.1039 - dense_1_loss: 6.0031 - dense_2_loss: 6.1008 - dense_1_acc: 0.0436 - dense_2_acc: 0.0221\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 11.8728 - dense_1_loss: 5.8928 - dense_2_loss: 5.9800 - dense_1_acc: 0.0466 - dense_2_acc: 0.0269\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 11.6422 - dense_1_loss: 5.7756 - dense_2_loss: 5.8666 - dense_1_acc: 0.0493 - dense_2_acc: 0.0319\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 11.4145 - dense_1_loss: 5.6668 - dense_2_loss: 5.7477 - dense_1_acc: 0.0538 - dense_2_acc: 0.0392\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 11.1825 - dense_1_loss: 5.5515 - dense_2_loss: 5.6309 - dense_1_acc: 0.0597 - dense_2_acc: 0.0458\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 10.9768 - dense_1_loss: 5.4519 - dense_2_loss: 5.5249 - dense_1_acc: 0.0653 - dense_2_acc: 0.0518\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 10.7682 - dense_1_loss: 5.3487 - dense_2_loss: 5.4195 - dense_1_acc: 0.0717 - dense_2_acc: 0.0585\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 10.5612 - dense_1_loss: 5.2459 - dense_2_loss: 5.3152 - dense_1_acc: 0.0753 - dense_2_acc: 0.0678\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 10.3524 - dense_1_loss: 5.1445 - dense_2_loss: 5.2079 - dense_1_acc: 0.0802 - dense_2_acc: 0.0762\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 10.1634 - dense_1_loss: 5.0559 - dense_2_loss: 5.1074 - dense_1_acc: 0.0893 - dense_2_acc: 0.0812\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.9767 - dense_1_loss: 4.9597 - dense_2_loss: 5.0171 - dense_1_acc: 0.0945 - dense_2_acc: 0.0867\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.8060 - dense_1_loss: 4.8791 - dense_2_loss: 4.9269 - dense_1_acc: 0.0994 - dense_2_acc: 0.0946\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.6381 - dense_1_loss: 4.7965 - dense_2_loss: 4.8416 - dense_1_acc: 0.1068 - dense_2_acc: 0.1020\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.4637 - dense_1_loss: 4.7105 - dense_2_loss: 4.7532 - dense_1_acc: 0.1150 - dense_2_acc: 0.1093\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.3218 - dense_1_loss: 4.6406 - dense_2_loss: 4.6812 - dense_1_acc: 0.1176 - dense_2_acc: 0.1132\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.1596 - dense_1_loss: 4.5584 - dense_2_loss: 4.6011 - dense_1_acc: 0.1246 - dense_2_acc: 0.1156\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 9.0047 - dense_1_loss: 4.4805 - dense_2_loss: 4.5241 - dense_1_acc: 0.1298 - dense_2_acc: 0.1247\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 8.8672 - dense_1_loss: 4.4155 - dense_2_loss: 4.4517 - dense_1_acc: 0.1334 - dense_2_acc: 0.1285\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 8.7344 - dense_1_loss: 4.3494 - dense_2_loss: 4.3850 - dense_1_acc: 0.1366 - dense_2_acc: 0.1309\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 8.6049 - dense_1_loss: 4.2834 - dense_2_loss: 4.3215 - dense_1_acc: 0.1419 - dense_2_acc: 0.1385\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 8.4648 - dense_1_loss: 4.2184 - dense_2_loss: 4.2463 - dense_1_acc: 0.1438 - dense_2_acc: 0.1469\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 160s 16ms/step - loss: 8.3550 - dense_1_loss: 4.1638 - dense_2_loss: 4.1912 - dense_1_acc: 0.1496 - dense_2_acc: 0.1482\n"
     ]
    }
   ],
   "source": [
    "batch_size = 160\n",
    "split = 10000\n",
    "\n",
    "model_history = model.fit([context_array[:split], question_array[:split]],\n",
    "                          [start_array[:split], end_array[:split]], verbose=1,\n",
    "                          batch_size=batch_size, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models\n"
     ]
    }
   ],
   "source": [
    "print('Saving models')\n",
    "model.save('squad_model.h5')\n",
    "modelW2V.save('w2vec_model.h5')\n",
    "with open('history_squad.json', 'w') as outfile:\n",
    "    json.dump(model_history.history, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 294s 15ms/step - loss: 10.6324 - dense_1_loss: 5.2697 - dense_2_loss: 5.3627 - dense_1_acc: 0.0820 - dense_2_acc: 0.0659\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 10.0700 - dense_1_loss: 4.9905 - dense_2_loss: 5.0795 - dense_1_acc: 0.0943 - dense_2_acc: 0.0791\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 9.7762 - dense_1_loss: 4.8467 - dense_2_loss: 4.9295 - dense_1_acc: 0.1042 - dense_2_acc: 0.0916\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 9.5593 - dense_1_loss: 4.7428 - dense_2_loss: 4.8165 - dense_1_acc: 0.1086 - dense_2_acc: 0.1001\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 9.3806 - dense_1_loss: 4.6554 - dense_2_loss: 4.7252 - dense_1_acc: 0.1166 - dense_2_acc: 0.1064\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 9.2246 - dense_1_loss: 4.5734 - dense_2_loss: 4.6512 - dense_1_acc: 0.1209 - dense_2_acc: 0.1119\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 9.0994 - dense_1_loss: 4.5148 - dense_2_loss: 4.5847 - dense_1_acc: 0.1238 - dense_2_acc: 0.1155\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.9918 - dense_1_loss: 4.4633 - dense_2_loss: 4.5285 - dense_1_acc: 0.1285 - dense_2_acc: 0.1221\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.8638 - dense_1_loss: 4.3986 - dense_2_loss: 4.4652 - dense_1_acc: 0.1331 - dense_2_acc: 0.1258\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.7579 - dense_1_loss: 4.3464 - dense_2_loss: 4.4115 - dense_1_acc: 0.1386 - dense_2_acc: 0.1310\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.6639 - dense_1_loss: 4.2998 - dense_2_loss: 4.3642 - dense_1_acc: 0.1394 - dense_2_acc: 0.1310\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.4819 - dense_1_loss: 4.2093 - dense_2_loss: 4.2727 - dense_1_acc: 0.1463 - dense_2_acc: 0.1404\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.3286 - dense_1_loss: 4.1322 - dense_2_loss: 4.1964 - dense_1_acc: 0.1504 - dense_2_acc: 0.1441\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.2501 - dense_1_loss: 4.0910 - dense_2_loss: 4.1591 - dense_1_acc: 0.1522 - dense_2_acc: 0.1458\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.2501 - dense_1_loss: 4.0910 - dense_2_loss: 4.1591 - dense_1_acc: 0.1522 - dense_2_acc: 0.1458\n",
      "Epoch 17/30\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.1766 - dense_1_loss: 4.0556 - dense_2_loss: 4.1209 - dense_1_acc: 0.1585 - dense_2_acc: 0.1535\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.1766 - dense_1_loss: 4.0556 - dense_2_loss: 4.1209 - dense_1_acc: 0.1585 - dense_2_acc: 0.1535\n",
      "Epoch 18/30\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.0985 - dense_1_loss: 4.0191 - dense_2_loss: 4.0794 - dense_1_acc: 0.1577 - dense_2_acc: 0.1517\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.0985 - dense_1_loss: 4.0191 - dense_2_loss: 4.0794 - dense_1_acc: 0.1577 - dense_2_acc: 0.1517\n",
      "Epoch 19/30\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.0188 - dense_1_loss: 3.9864 - dense_2_loss: 4.0324 - dense_1_acc: 0.1606 - dense_2_acc: 0.1555\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 8.0188 - dense_1_loss: 3.9864 - dense_2_loss: 4.0324 - dense_1_acc: 0.1606 - dense_2_acc: 0.1555\n",
      "Epoch 20/30\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 292s 15ms/step - loss: 7.9605 - dense_1_loss: 3.9500 - dense_2_loss: 4.0105 - dense_1_acc: 0.1645 - dense_2_acc: 0.1557\n",
      "20000/20000 [==============================] - 292s 15ms/step - loss: 7.9605 - dense_1_loss: 3.9500 - dense_2_loss: 4.0105 - dense_1_acc: 0.1645 - dense_2_acc: 0.1557\n",
      "Epoch 21/30\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8844 - dense_1_loss: 3.9179 - dense_2_loss: 3.9665 - dense_1_acc: 0.1656 - dense_2_acc: 0.1620\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8844 - dense_1_loss: 3.9179 - dense_2_loss: 3.9665 - dense_1_acc: 0.1656 - dense_2_acc: 0.1620\n",
      "Epoch 22/30\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.9865 - dense_1_loss: 3.9652 - dense_2_loss: 4.0213 - dense_1_acc: 0.1602 - dense_2_acc: 0.1565\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.9865 - dense_1_loss: 3.9652 - dense_2_loss: 4.0213 - dense_1_acc: 0.1602 - dense_2_acc: 0.1565\n",
      "Epoch 23/30\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8832 - dense_1_loss: 3.9111 - dense_2_loss: 3.9721 - dense_1_acc: 0.1597 - dense_2_acc: 0.1613\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8832 - dense_1_loss: 3.9111 - dense_2_loss: 3.9721 - dense_1_acc: 0.1597 - dense_2_acc: 0.1613\n",
      "Epoch 24/30\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.7919 - dense_1_loss: 3.8687 - dense_2_loss: 3.9232 - dense_1_acc: 0.1641 - dense_2_acc: 0.1618\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.7919 - dense_1_loss: 3.8687 - dense_2_loss: 3.9232 - dense_1_acc: 0.1641 - dense_2_acc: 0.1618\n",
      "Epoch 25/30\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8310 - dense_1_loss: 3.8847 - dense_2_loss: 3.9463 - dense_1_acc: 0.1650 - dense_2_acc: 0.1603\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.8310 - dense_1_loss: 3.8847 - dense_2_loss: 3.9463 - dense_1_acc: 0.1650 - dense_2_acc: 0.1603\n",
      "Epoch 26/30\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.7073 - dense_1_loss: 3.8265 - dense_2_loss: 3.8808 - dense_1_acc: 0.1699 - dense_2_acc: 0.1643\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.7073 - dense_1_loss: 3.8265 - dense_2_loss: 3.8808 - dense_1_acc: 0.1699 - dense_2_acc: 0.1643\n",
      "Epoch 27/30\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.6365 - dense_1_loss: 3.7931 - dense_2_loss: 3.8434 - dense_1_acc: 0.1732 - dense_2_acc: 0.1678\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.6365 - dense_1_loss: 3.7931 - dense_2_loss: 3.8434 - dense_1_acc: 0.1732 - dense_2_acc: 0.1678\n",
      "Epoch 28/30\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.5472 - dense_1_loss: 3.7498 - dense_2_loss: 3.7975 - dense_1_acc: 0.1753 - dense_2_acc: 0.1760\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.5472 - dense_1_loss: 3.7498 - dense_2_loss: 3.7975 - dense_1_acc: 0.1753 - dense_2_acc: 0.1760\n",
      "Epoch 29/30\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.4756 - dense_1_loss: 3.7151 - dense_2_loss: 3.7605 - dense_1_acc: 0.1783 - dense_2_acc: 0.1747\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.4756 - dense_1_loss: 3.7151 - dense_2_loss: 3.7605 - dense_1_acc: 0.1783 - dense_2_acc: 0.1747\n",
      "Epoch 30/30\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.4310 - dense_1_loss: 3.6898 - dense_2_loss: 3.7412 - dense_1_acc: 0.1772 - dense_2_acc: 0.1778\n",
      "20000/20000 [==============================] - 293s 15ms/step - loss: 7.4310 - dense_1_loss: 3.6898 - dense_2_loss: 3.7412 - dense_1_acc: 0.1772 - dense_2_acc: 0.1778\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "split = 20000\n",
    "\n",
    "model_history = model.fit([context_array[:split], question_array[:split]],\n",
    "                          [start_array[:split], end_array[:split]], verbose=1,\n",
    "                          batch_size=batch_size, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models\n"
     ]
    }
   ],
   "source": [
    "print('Saving models')\n",
    "model.save('squad_model.h5')\n",
    "with open('history_squad2.json', 'w') as outfile:\n",
    "    json.dump(model_history.history, outfile)\n",
    "    \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar esta fase de entrenamiento, se guardan los datos del historial de entrenamiento y los pesos del Word2Vec y del modelo entrenado y se procede a limpiar la memoria para dejar todo en limpio e iniciar la fase de testing.\n",
    "\n",
    "### Parte 9\n",
    "Basandonos en el ejemplo de evaluación del dataset SQuAD se agregan las funciones que permitan evaluar y procesar los archivos de test y resultados de la predicción para así conseguir las métricas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def evaluate(dataset, predictions):\n",
    "    f1 = exact_match = total = 0\n",
    "    for article in dataset:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                total += 1\n",
    "                if qa['id'] not in predictions:\n",
    "                    message = 'Unanswered question ' + qa['id'] + \\\n",
    "                              ' will receive score 0.'\n",
    "                    print(message, file=sys.stderr)\n",
    "                    continue\n",
    "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
    "                prediction = predictions[qa['id']]\n",
    "                exact_match += metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction, ground_truths)\n",
    "                f1 += metric_max_over_ground_truths(\n",
    "                    f1_score, prediction, ground_truths)\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return {'exact_match': exact_match, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con las funciones necesarias, se carga desde el disco los pesos del modelo entrenado y el bag of words. Se procede a cargar los párrafos y las preguntas del dataset de prueba, pasarlos a la estructura que el modelo pide y proceder a la fase de predicción, donde se almacenan las respuestas en un diccionario en formato JSON siguiendo el formato que SQuAD sugiere para la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Finished reading and preprocessing documents\n",
      "(10570, 679)\n",
      "(10570, 50)\n",
      "10570/10570 [==============================] - 143s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('squad_model.h5')\n",
    "modelW2V = gensim.models.Word2Vec.load(\"w2vec_model.h5\")\n",
    "\n",
    "with(open('dev-v1.1.json')) as json_data:\n",
    "    d = json.load(json_data)\n",
    "\n",
    "dataset = d['data']\n",
    "print(len(dataset))\n",
    "\n",
    "context_list = []\n",
    "context_entire = []\n",
    "question_list = []\n",
    "question_entire = []\n",
    "question_ids = []\n",
    "answers = []\n",
    "\n",
    "context_size = 679\n",
    "question_size = 50\n",
    "\n",
    "CUSTOM_FILTER = [\n",
    "    lambda x: x.lower(), p.strip_tags, p.strip_punctuation,\n",
    "    p.strip_multiple_whitespaces\n",
    "]\n",
    "\n",
    "for article in dataset:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = p.preprocess_string(paragraph['context'], CUSTOM_FILTER)\n",
    "        if len(context) > context_size:\n",
    "            context_size = len(context)\n",
    "\n",
    "        for qa in paragraph['qas']:\n",
    "            question = p.preprocess_string(qa['question'], CUSTOM_FILTER)\n",
    "            if len(question) > question_size:\n",
    "                question_size = len(question)\n",
    "            context_list.append(context)\n",
    "            context_entire.append(paragraph['context'])\n",
    "            question_list.append(question)\n",
    "            question_entire.append(qa['question'])\n",
    "            question_ids.append(qa['id'])\n",
    "\n",
    "print(\"Finished reading and preprocessing documents\")\n",
    "\n",
    "context_array = np.zeros((len(context_list), context_size), dtype='int32')\n",
    "question_array = np.zeros((len(question_list), question_size), dtype='int32')\n",
    "\n",
    "for i in range(len(context_list)):\n",
    "    for j in range(len(context_list[i])):\n",
    "        try:\n",
    "            context_array[i][j] = modelW2V.wv.vocab[context_list[i][j]].index\n",
    "        except KeyError:\n",
    "            context_array[i][j] = 0\n",
    "\n",
    "for i in range(len(question_list)):\n",
    "    for j in range(len(question_list[i])):\n",
    "        try:\n",
    "            question_array[i][j] = modelW2V.wv.vocab[question_list[i][j]].index\n",
    "        except KeyError:\n",
    "            question_array[i][j] = 0\n",
    "\n",
    "print(context_array.shape)\n",
    "print(question_array.shape)\n",
    "predictions = model.predict([context_array, question_array], verbose=1)\n",
    "\n",
    "starts = predictions[0]\n",
    "ends = predictions[1]\n",
    "\n",
    "response = {}\n",
    "for i in range(len(starts)):\n",
    "    response[question_ids[i]] = context_entire[i][np.argmax(starts[i]):np.argmax(ends[i])]\n",
    "\n",
    "with open('train_result.json', 'w') as outfile:\n",
    "    json.dump(response, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se procede a la fase de evaluaación, donde se cargan los archivos de test junto a las respuestas obtenidas por el modelo y se llama a las funciones correspondientes para su evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"exact_match\": 0.30274361400189215, \"f1\": 2.2069435388678484}\n"
     ]
    }
   ],
   "source": [
    "expected_version = '1.1'\n",
    "with open('dev-v1.1.json') as dataset_file:\n",
    "    dataset_json = json.load(dataset_file)\n",
    "    if dataset_json['version'] != expected_version:\n",
    "        print('Evaluation expects v-' + expected_version +\n",
    "              ', but got dataset with v-' + dataset_json['version'],\n",
    "              file=sys.stderr)\n",
    "    dataset = dataset_json['data']\n",
    "with open('train_result.json') as prediction_file:\n",
    "    predictions = json.load(prediction_file)\n",
    "print(json.dumps(evaluate(dataset, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el resultado obtenido es bastante pobre, hay varias suposiciones al respecto de porque sucede esto:\n",
    "- Para empezar, en la fase de entrenamiento se llegó a un accuracy de un 17% aproximadamente comparandose con los propios datos de entrenmiento. Igualmente la función de perdida nunca dejo ser un valor alto, por lo tanto hace suponer que el modelo estaba muy lejos para converger, y por último, despues de varios epochs se observaba que el modelo empezaba a saturarse. Esto permite concluir que el modelo no estaba aprendiendo y lo poco que aprendia lo hacia de memoria.\n",
    "- El modelo usado es muy probablemente que pueda ser mejorado agregando algunas capas ocultas más que permitan extraer más features del texto.\n",
    "- Igualmente podría ser beneficioso hacer un mejor procesamiento del vocabulario. Tal vez haciendo que este sea mucho más rico en palabras.\n",
    "- Es probable que el tipo de neuronas ocupadas en el modelo no eran las adecuadas o tal vez era necesario hacer un mayor tunning al respecto.\n",
    "\n",
    "Como trabajo futuro se espera poder entrenar un mejor modelo para así lograr resolver el problema de Pregunta/Respuesta planteado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}